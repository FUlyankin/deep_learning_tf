{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXaN4pH4pRSj"
   },
   "source": [
    "# Generative Adversarial Network (GAN)\n",
    "\n",
    "![](https://nbviewer.jupyter.org/github/hse-aml/intro-to-dl/blob/master/week4/images/gan.png)\n",
    "\n",
    "Пришло время поговорить о более интересных архитектурах, а именно о GANах или состязательных нейронных сетках. [Впервые GANы были предложены в 2014 году.](https://arxiv.org/abs/1406.2661) Сейчас они очень активно исследуются. GANы состоят из двух нейронных сетей: \n",
    "\n",
    "* Первая - генератор порождает из некоторого заданного распределения случайные числа и собирает из них объекты, которые идут на вход второй сети. \n",
    "* Вторая - дискриминатор получает на вход объекты из реальной выборки и объекты, созданные генератором. Она пытается определить какой объект был порождён генератором, а какой является реальным.\n",
    "\n",
    "Таким образом генератор пытается создавать объекты, которые дискриминатор не сможет отличить от реальных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sbKtr3CrpRSm",
    "outputId": "51c12158-e9ac-4671-b66a-2dd368a00404"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhUuDVvxpRSt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kckbb4Y7pRSv"
   },
   "source": [
    "# 1. Данные\n",
    "\n",
    "Для начала давайте попробуем погонять модели на рукописных цифрах из MNIST как бы скучно это не было. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "iz73STykpRSy",
    "outputId": "025bee36-1f88-4d45-9d9c-f24265537542"
   },
   "outputs": [],
   "source": [
    "(X, _ ), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exSIyRN_pRS0"
   },
   "outputs": [],
   "source": [
    "X = X/127.5 - 1 # отнормировали данные на отрезок [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.min(), X.max()  # проверили нормировку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Za9NAhDnpRS-",
    "outputId": "dbc2747f-c763-4da9-f6cc-c9a00c39ae6e"
   },
   "outputs": [],
   "source": [
    "X = X[:,:,:,np.newaxis]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVqtKuyrpRTB"
   },
   "source": [
    "Давайте вытащим несколько рандомных картинок и нарисуем их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "m-i19NcMpRTC",
    "outputId": "736d9121-d672-49b2-d6ac-c4e5754cd550"
   },
   "outputs": [],
   "source": [
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, X.shape[0])\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid(False)\n",
    "        ax.axis('off')\n",
    "        ax.imshow(np.squeeze(X,-1)[random_index, :], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберём для наших данных удобный генератор. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvWGxGQzpRTE"
   },
   "source": [
    "# 2. Дискриминатор \n",
    "\n",
    "* Дискриминатор - это обычная свёрточная сетка \n",
    "* Цель этой сетки - отличать сгенерированные изображения от реальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yr_Nm2JDpRTF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKCQcxILpRTH"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1M_SaSfHpRTK"
   },
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "\n",
    "# Ваш код \n",
    "\n",
    "# слой Conv2D 64  фильтра, kernel size 5x5, страйд 2 по обеим осям\n",
    "# бачнорм + LeakyReLU()\n",
    "# слой Conv2D 128  фильтров, kernel size 5x5, страйд 2 по обеим осям\n",
    "# бачнорм + LeakyReLU()\n",
    "# Flatten\n",
    "# классификация на 2 класса\n",
    "\n",
    "\n",
    "# на выход из дискриминатора мы забираем логарифм, а не вероятность \n",
    "discriminator.add(L.Dense(2, activation=tf.nn.log_softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uvxieLDvpRTM"
   },
   "source": [
    "# 3. Генератор\n",
    "\n",
    "* Генерирует из шума изображения \n",
    "\n",
    "Будем генерировать новых Симпсонов из шума размера 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LA2KnUT5pRTN"
   },
   "outputs": [],
   "source": [
    "CODE_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GmKZQvxvpRTP",
    "outputId": "4281d592-6b0f-4f57-cb9d-10ec572a88f7"
   },
   "outputs": [],
   "source": [
    "generator = Sequential()\n",
    "\n",
    "generator.add(L.InputLayer([CODE_SIZE],name='noise'))\n",
    "\n",
    "generator.add(L.Dense(256*7*7, activation='elu'))\n",
    "generator.add(L.Reshape((7,7,256)))\n",
    "\n",
    "generator.add(L.Conv2DTranspose(128, kernel_size=(3,3)))\n",
    "generator.add(L.LeakyReLU())\n",
    "\n",
    "generator.add(L.Conv2DTranspose(64, kernel_size=(3,3)))\n",
    "generator.add(L.LeakyReLU())\n",
    "\n",
    "generator.add(L.UpSampling2D(size=(2,2)))\n",
    "generator.add(L.Conv2DTranspose(32,kernel_size=3,activation='elu'))\n",
    "generator.add(L.Conv2DTranspose(32,kernel_size=3,activation='elu'))\n",
    "generator.add(L.Conv2DTranspose(32,kernel_size=3,activation='elu'))\n",
    "\n",
    "generator.add(L.Conv2D(1, kernel_size=3, padding='same'))\n",
    "\n",
    "print('Выход генератора: ', generator.output_shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHOMInsGpRTR"
   },
   "source": [
    "Посмотрим на пример, который нам генерирует на выход наша свежая нейронка! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, CODE_SIZE])\n",
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UkdTF5zVpRTS",
    "outputId": "29fc84a6-51e6-4fe0-8777-036b826f85f3"
   },
   "outputs": [],
   "source": [
    "generated_image =  generator(noise)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8natz3KKpRTU"
   },
   "source": [
    "Хммм... А что про это всё думает дескриминатор?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IetKwYPjpRTV",
    "outputId": "a137554c-4969-4de0-fd4b-f7fec50aec92"
   },
   "outputs": [],
   "source": [
    "decision = discriminator(generated_image)\n",
    "\n",
    "# на выход из дискриминатора мы забираем логарифм!\n",
    "np.exp(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iL4-BUjtpRTY"
   },
   "source": [
    "# 4. Функция потерь "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OUgY-lrpRTZ"
   },
   "source": [
    "Потери для дескриминатора это обычныя кросс-энтропия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2jXGozlpRTa"
   },
   "outputs": [],
   "source": [
    "# Потери для дискриминатора \n",
    "def discriminator_loss(logp_real, logp_gen):\n",
    "\n",
    "    # Ваш код\n",
    "\n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "Tiz-y9OupRTd",
    "outputId": "b16c773f-1374-4c4f-e132-59220fb6d3e2"
   },
   "outputs": [],
   "source": [
    "real_log = discriminator(X[:1])\n",
    "gen_log = discriminator(generated_image)\n",
    "\n",
    "discriminator_loss(real_log, gen_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6PABXZTpRTf"
   },
   "source": [
    "Для генератора мы хотим максимизировать ошибку дискриминатора на фэйковых примерах. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9r_eUzmpRTg"
   },
   "outputs": [],
   "source": [
    "# Потери для генератора\n",
    "def generator_loss(logp_gen):\n",
    "    \n",
    "    # Ваш код \n",
    "    \n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rt-LiofmpRTj",
    "outputId": "a8662b74-fc3d-4d6c-f167-2be9952e63a9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_loss(gen_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6Fk5J4CpRTp"
   },
   "source": [
    "# 5. Градиентный спуск\n",
    "\n",
    "Учить пару из сеток будем так: \n",
    "\n",
    "* Делаем $k$ шагов обучения дискриминатора. Целевая переменная - реальный объект перед нами или порождённый. Веса изменяем стандартно, пытаясь уменьшить кросс-энтропию.\n",
    "* Делаем $m$ шагов обучения генератора. Веса внутри сетки меняем так, чтобы увеличить логарифм вероятности дискриминатора присвоить сгенерированному объекту лэйбл реального. \n",
    "* Обучаем итеративно до тех пор, пока дискриминатор больше не сможет найти разницу (либо пока у нас не закончится терпение).\n",
    "* При обучении может возникнуть огромное количество пробем от взрыва весов до более тонких вещей. Имеет смысл посмотреть на разные трюки, используемые при обучении:  https://github.com/soumith/ganhacks\n",
    "\n",
    "Собираем структуру для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKbQTq5dpRTs"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "#discriminator_optimizer = tf.keras.optimizers.SGD(1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmjZ9UxfpRTu"
   },
   "source": [
    "Чекпойнты для процесса обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHgG-4vYpRTv"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y3KnodoJpRTx"
   },
   "source": [
    "Задаём один шаг процедуры обучения генератора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7E7MBIBpRTx"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_generator_step(images, noise):\n",
    "\n",
    "    # ищем градиенты \n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        \n",
    "        # ВАШ КОД\n",
    "        \n",
    "        # сгенерировали новое изображение из шума\n",
    "        # посчитали прогнозы дискриминатора\n",
    "        # нашли ошибку\n",
    "        gen_loss = ...\n",
    "        \n",
    "    # нашли градиенты\n",
    "    grad = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        \n",
    "    # сделали шаг градиентного спуска \n",
    "    generator_optimizer.apply_gradients(zip(grad, generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIZUae_NpRT0"
   },
   "source": [
    "Теперь шаг обучения дискриминатора. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjEexY2OpRT0"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_discriminator_step(images, noise):\n",
    "    \n",
    "   # ищем градиенты \n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        \n",
    "        # ВАШ КОД\n",
    "        \n",
    "        # сгенерировали новое изображение из шума       \n",
    "        # посчитали прогнозы дискриминатора\n",
    "        # нашли ошибку\n",
    "        dis_loss = ...\n",
    "        \n",
    "    # нашли градиенты\n",
    "    grad = gen_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
    "        \n",
    "    # сделали шаг градиентного спуска \n",
    "    generator_optimizer.apply_gradients(zip(grad, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Обратите внимание, что можно реализовать функцию для обучения сразу для обеих нейронок, а не как мы по отдельности. В случае совместной реализации код будет работать быстрее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhpbZYv6pRT2"
   },
   "source": [
    "Мы почти готовы учить нашу сетку. Напишем две простенькие функции для генерации фэйковых и настоящих батчей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6u0IoKRpRT3"
   },
   "outputs": [],
   "source": [
    "# функция, которая генерирует батч с шумом\n",
    "def sample_noise_batch(bsize):\n",
    "    return tf.random.normal([bsize, CODE_SIZE], dtype=tf.float32)\n",
    "\n",
    "# функция, которая генерирует батч из реальных данных (для баловства)\n",
    "def sample_data_batch(bsize):\n",
    "    idxs = np.random.choice(np.arange(X.shape[0]), size=bsize)\n",
    "    return X[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKb5nRbVpRT4"
   },
   "source": [
    "Проверяем отрабатывают ли наши шаги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "tag4OrE_pRT5",
    "outputId": "5277fa7f-15d2-48cb-e52f-452ade58b71f"
   },
   "outputs": [],
   "source": [
    "data_test = sample_data_batch(256)\n",
    "fake_test = sample_noise_batch(256)\n",
    "\n",
    "gen_log = discriminator(generator(fake_test))\n",
    "real_log = discriminator(data_test)\n",
    "\n",
    "print('Ошибка дескриминатора:', discriminator_loss(real_log, gen_log).numpy())\n",
    "print('Ошибка генератора:', generator_loss(gen_log).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделали шаг работы генератора\n",
    "train_generator_step(data_test, fake_test)\n",
    "\n",
    "gen_log = discriminator(generator(fake_test))\n",
    "real_log = discriminator(data_test)\n",
    "\n",
    "print('Ошибка дескриминатора:', discriminator_loss(real_log, gen_log).numpy())\n",
    "print('Ошибка генератора:', generator_loss(gen_log).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "hel7ec2YpRT7",
    "outputId": "be193556-ee5a-4f20-b1f5-3b6c232b1ecc"
   },
   "outputs": [],
   "source": [
    "# сделали шаг работы дискриминатора\n",
    "train_discriminator_step(data_test, fake_test)\n",
    "\n",
    "gen_log = discriminator(generator(fake_test))\n",
    "real_log = discriminator(data_test)\n",
    "\n",
    "print('Ошибка дескриминатора:', discriminator_loss(real_log, gen_log).numpy())\n",
    "print('Ошибка генератора:', generator_loss(gen_log).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llLaVh-lpRUD"
   },
   "source": [
    "Как думаете, выглядит адекватно? Мы нигде не ошиблись? \n",
    "\n",
    "Напишем пару вспомогательных функций для отрисовки картинок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgqyoSxipRUE"
   },
   "outputs": [],
   "source": [
    "# рисуем изображения\n",
    "def sample_images(rows, cols, num=0):\n",
    "    images = generator.predict(sample_noise_batch(bsize=rows*cols))\n",
    "    \n",
    "    fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
    "    for i in range(cols):\n",
    "        for j in range(rows):\n",
    "            ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "            ax.grid('off')\n",
    "            ax.axis('off')\n",
    "            ax.imshow(np.squeeze(images[i * rows + j],-1),cmap='gray')\n",
    "    \n",
    "    # сохраняем картинку для гифки\n",
    "    if num >0:\n",
    "        plt.savefig('images_gan/image_at_epoch_{:04d}.png'.format(num))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# рисуем распределения\n",
    "def sample_probas(X):\n",
    "    plt.title('Generated vs real data')\n",
    "    \n",
    "    plt.hist(np.exp(discriminator.predict(X))[:,1],\n",
    "             label='D(x)', alpha=0.5,range=[0,1])\n",
    "    \n",
    "    plt.hist(np.exp(discriminator.predict(generator.predict(sample_noise_batch(X.shape[0]))))[:,1],\n",
    "             label='D(G(z))',alpha=0.5,range=[0,1])\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "4sRT2SDnpRUG",
    "outputId": "85c2170c-8162-4cea-bc17-eaa0f7590c64"
   },
   "outputs": [],
   "source": [
    "sample_images(2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "baEw1cdnpRUI",
    "outputId": "9bcdea14-d47d-4a55-c82f-28622c54dbab"
   },
   "outputs": [],
   "source": [
    "sample_probas(X[:100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного побалуемся с шагами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = sample_data_batch(256)\n",
    "fake_test = sample_noise_batch(256)\n",
    "\n",
    "# Генератор\n",
    "train_generator_step(data_test, fake_test)\n",
    "\n",
    "gen_log = discriminator(generator(fake_test))\n",
    "real_log = discriminator(data_test)\n",
    "\n",
    "print('Ошибка дескриминатора:', discriminator_loss(real_log, gen_log).numpy())\n",
    "print('Ошибка генератора:', generator_loss(gen_log).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images(2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = sample_data_batch(256)\n",
    "fake_test = sample_noise_batch(256)\n",
    "\n",
    "# Дискриминатор\n",
    "train_discriminator_step(data_test, fake_test)\n",
    "\n",
    "gen_log = discriminator(generator(fake_test))\n",
    "real_log = discriminator(data_test)\n",
    "\n",
    "print('Ошибка дескриминатора:', discriminator_loss(real_log, gen_log).numpy())\n",
    "print('Ошибка генератора:', generator_loss(gen_log).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mG26Axj8pRUK"
   },
   "source": [
    "# 6. Обучение\n",
    "\n",
    "Ну и наконец последний шаг. Тренировка сеток.  При обучении нужно соблюдать между сетками баланс. Важно сделать так, чтобы ни одна из них не стала сразу же побеждать. Иначе обучение остановится. \n",
    "\n",
    "* Чтобы избежать моментального выигрыша дискриминатора, мы добавили в его функцию потерь $l_2$ регуляризацию. \n",
    "* Кроме регуляризации можно пытаться учить модели сбалансированно, делая внутри цикла шаги чуть более умным способом. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "EPOCHS = 5000\n",
    "BSIZE = 256\n",
    "\n",
    "# время\n",
    "start = time.time()/60\n",
    "\n",
    "# вектора для мониторинга сходимости сеток\n",
    "d_losses = [ ]\n",
    "g_losses = [ ]\n",
    "\n",
    "num = 0 # для сохранения картинок \n",
    "\n",
    "# запускаем цикл обучения \n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # генерируем батч\n",
    "    X_batch = sample_data_batch(BSIZE)\n",
    "    X_fake = sample_noise_batch(BSIZE)\n",
    "    \n",
    "    # делаем N шагов обучения дискриминатора\n",
    "    for i in range(5):\n",
    "        train_discriminator_step(X_batch, X_fake)\n",
    "        \n",
    "    # делаем K шагов обучения генератора\n",
    "    for i in range(1):\n",
    "        train_generator_step(X_batch, X_fake)\n",
    "\n",
    "    gen_log = discriminator(generator(X_fake))\n",
    "    real_log = discriminator(X_batch) \n",
    "    \n",
    "    d_losses.append(discriminator_loss(real_log, gen_log).numpy())\n",
    "    g_losses.append(generator_loss(gen_log).numpy())\n",
    "        \n",
    "    # ну сколько можно ждааать!!! \n",
    "    if epoch % 1==0:\n",
    "        print('Time for epoch {} is {} min'.format(epoch + 1, time.time()/60-start))\n",
    "        print('error D: {}, error G: {}'.format(d_losses[-1], g_losses[-1]))\n",
    "\n",
    "    if epoch % 10==0:\n",
    "        # сохраняем модель и обновляем картинку\n",
    "        # checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        # можно раскоментировать, если хочется, чтобы картинка обновлялась, а не дополнялас\n",
    "        #display.clear_output(wait=True)\n",
    "        num += 1\n",
    "        sample_images(2,7, num)\n",
    "        sample_probas(X_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Qso__0apRUQ"
   },
   "source": [
    "Тренируем сетки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2T6ddJLJpRUR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# сетка тренировалась много итераций\n",
    "sample_images(4,8)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-4JKb0VpRUS",
    "outputId": "f2e4bc20-c8ff-4626-e18a-9cd177af8054"
   },
   "outputs": [],
   "source": [
    "# смотрим сошлись ли потери\n",
    "plt.plot(d_losses, label='Discriminator')\n",
    "plt.plot(g_losses, label='Generator')\n",
    "plt.ylabel('loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Интерполяция \n",
    "\n",
    "Давайте попробуем взять два вектора, сгенерированных из нормального распределения и посмотреть как один из них перетекакет в другой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def show_interp_samples(point1, point2, N_samples_interp):\n",
    "    N_samples_interp_all = N_samples_interp + 2\n",
    "\n",
    "    # линия между двумя точками\n",
    "    line = interp1d([1, N_samples_interp_all], np.vstack([point1, point2]), axis=0)\n",
    "\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    for i in range(N_samples_interp_all):\n",
    "        ax = fig.add_subplot(1, 2 + N_samples_interp, i+1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(generator.predict(line(i + 1).reshape((1, 100)))[0, :, :, 0],cmap='gray')\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "\n",
    "# Рандомная точка в пространстве\n",
    "noise_1 = np.random.normal(0, 1, (1, 100))\n",
    "\n",
    "# смотрим как она перетекает в симметричкную\n",
    "show_interp_samples(noise_1, -noise_1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_2 = np.random.normal(0, 1, (1, 100))\n",
    "show_interp_samples(noise_1, noise_2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что мы вообще сгенерировали?! Давайте посмотрим на точку из выборки наиболее близкую к получившейся генерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_label_sample = 8\n",
    "img_smp = generator.predict(sample_noise_batch(1))\n",
    "plt.imshow(img_smp[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_smp.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ищем l1 норму между тем, что сгенерилось и остальным \n",
    "L1d = np.sum(np.sum(np.abs(X[:,:,:,0] - img_smp[:,:,:,0]), axis=1), axis=1)\n",
    "idx_l1_sort = L1d.argsort()\n",
    "idx_l1_sort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_l1_sort[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_closest = 8\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "for i in range(N_closest):\n",
    "    ax = fig.add_subplot(1, N_closest, i+1)\n",
    "    ax.grid('off')\n",
    "    ax.axis('off')\n",
    "    ax.imshow(X[idx_l1_sort[i], :, :, 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняю гифку из картинок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "def create_animated_gif(files, animated_gif_name, pause=0):\n",
    "    if pause != 0:\n",
    "        \n",
    "        frames = []\n",
    "        for file in files:\n",
    "            count = 0\n",
    "            while count < pause:\n",
    "                frames.append(file)\n",
    "                count+=1\n",
    "        print(\"Total number of frames in the animation:\", len(frames))\n",
    "        files = frames\n",
    "    images = [imageio.imread(file) for file in files]\n",
    "    imageio.mimsave(animated_gif_name, images, duration = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pause = 1\n",
    "animated_gif_name = 'animation_GAN.gif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images_gan/*.png'\n",
    "files = glob.glob(image_path)\n",
    "files = sorted(files, key = lambda w: int(w.split('_')[-1].split('.')[0]))\n",
    "create_animated_gif(files, animated_gif_name, pause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание : \n",
    "\n",
    "* Превратить нашу GAN в Conditional GAN \n",
    "\n",
    "![](https://camo.githubusercontent.com/63a263678253a1eedd74432ad85751da2407a3d8/687474703a2f2f6775696d70657261726e61752e636f6d2f66696c65732f626c6f672f46616e7461737469632d47414e732d616e642d77686572652d746f2d66696e642d7468656d2f6347414e5f6f766572766965772e6a7067)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykG2PeDgpRUl"
   },
   "source": [
    "На этом всё :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EfPgQIGMpRUo"
   },
   "source": [
    "![](https://miro.medium.com/max/896/1*3VOLkgm-QY05gEpGDkBzTA.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1N7FM1gvpRUo"
   },
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GAN_simpsons.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
