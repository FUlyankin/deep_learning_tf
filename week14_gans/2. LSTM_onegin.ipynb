{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Порождающая RNN\n",
    "\n",
    "Эта тетрадка основана на 6 главе Николенко. Пришло время обучить на каком-нибудь корпусе текстов порождающую нейронную сетку. Для того, чтобы делать это, нужно переработать тексты в приемлимые для работы датасеты. Идея, находящаяся под капотом очень проста: __давайте будем порождать текст буква за буквой,__ рассматривая его как поток символов. Тогда задача очень легко формализуется. Нужно предсказать следущий символ по текущему, то есть на каждом шаге нужно по накопленной истории решать задачу классификации на десяток классов.\n",
    "\n",
    "Вопрос в том, как для такой модели определить тренировочные данные.\n",
    "\n",
    "* __Первый, самый простой вариант__ - взять текст и разбить его на последовательности фиксированной длинны (окна) и предсказывать следущий по предыдущим. В такой ситуации начало и конец тренировочного примера будут довольно \"внезапными\", и артефакты по краям будут мешать генерировать на выходе хороший текст.\n",
    "* __Второй вариант__ - дробить текст на последовательности разной длины, но не слишком большой. Например, на предложения. Затем мы добавим спецсимволы начала и конца предложения и дополним каждую строчку до ммаксимума спецсимволом, означающим пустоту.\n",
    "* __Третий вариант__ - нарезать текст на последовательности примерно одной длины, но при этом правильным образом инициализировать скрытые состояния сетки. Для этого нужно взять наш длинный-длинный вход и превратить его сначала в достаточно широкий прямоугольник размера $N \\times L$, где $L$ - длина каждого тренировочного примера, а $N$ - число тренировочных примеров в исходной последовательности. Пока что $L$ очень велика. Но мы можем разрезать прямоугольник на более маленькие батчи по вертикали. Получиться, что каждый новый батч - продолжение предыдущего и его нужно обучать не с нуля, а с того скрытого состояния, на котором закончился предыдущий батч. \n",
    "\n",
    "Мы будем использовать второй вариант и просто дробить текст на предложения. \n",
    "\n",
    "## 1. Предобработка выборки\n",
    "\n",
    "Будем строить модельна примери Евгения Онегина. Считаем данные, определим три специальных символа: `START_CHAR` будет подставляться перед началом предложеия, `END_CHAR` после его конца, а `PADDING_CHAR` будет заполнять остаток предложения до максимума длины. Для простоты мы также не будетм различать строчные и заглавные буквы, а просто пропустим каждую строчку через `lower()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_CHAR = '\\b'\n",
    "END_CHAR = '\\t'\n",
    "PADDING_CHAR = '\\a'\n",
    "\n",
    "chars = set([START_CHAR, '\\n', END_CHAR])\n",
    "\n",
    "with open('onegin.txt') as f:\n",
    "    for line in f:\n",
    "        chars.update(list(line.strip().lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заведём словари с отображением символов в числа и обратно    \n",
    "char_indices = { c : i+1 for i,c in enumerate(sorted(list(chars))) }\n",
    "char_indices[PADDING_CHAR] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_chars = { i : c for c,i in char_indices.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_chars = len(indices_to_chars)\n",
    "num_chars # уникальные символы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим векторные представления для символов. Это будет просто OHE представления, в котором каждому символу соответствует вектор с одной единицей, за исключением PADDING_CHAR, который будет представляться просто нулевым вектором. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_one(i, sz):\n",
    "    res = np.zeros(sz)\n",
    "    res[i] = 1\n",
    "    return res\n",
    "\n",
    "char_vectors = {\n",
    "    c : get_one(v, num_chars) for c,v in char_indices.items()\n",
    "}\n",
    "\n",
    "char_vectors['б']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь считаем исходный файл ещё разок. На этот раз разобьём его на предложения. Будем брать только предложения длиннее 10 символов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'театр уж полон; ложи блещут;\\nпартер и кресла, все кипит;\\nв райке нетерпеливо плещут,\\nи, взвившись, занавес шумит.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_end_markers = set('.!?')\n",
    "\n",
    "sentences = [ ]\n",
    "current_sentence = ''\n",
    "with open('onegin.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        s = line.strip().lower()\n",
    "        if len(s) > 0:\n",
    "            current_sentence += s + '\\n'\n",
    "        if len(s) == 0 or s[-1] in sentence_end_markers:\n",
    "            current_sentence = current_sentence.strip()\n",
    "            if len(current_sentence) > 10:\n",
    "                sentences.append(current_sentence)\n",
    "            current_sentence = ''\n",
    "            \n",
    "sentences[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1199"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следущий шаг - векторизация. Давайте определим процедуру, которая превращает набор предложений в два тензора: $X$ содержит векторы символов, а $Y$ результат, который нам нужно предсказать. Это на самом деле ровно тот же тензор $X$, только сдвинутый на один вектор влево: во время $t$ мы предсказываем символ, который будет стоять на месте $t+1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrices(sentences):\n",
    "    max_sentence_len = np.max([len(x) for x in sentences])\n",
    "    X = np.zeros((len(sentences), max_sentence_len, len(indices_to_chars)), dtype = np.bool)\n",
    "    Y = np.zeros((len(sentences), max_sentence_len, len(indices_to_chars)), dtype = np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        char_seq = (START_CHAR + sentence + END_CHAR).ljust(\n",
    "                      max_sentence_len + 1, PADDING_CHAR)\n",
    "        for t in range(max_sentence_len):\n",
    "            X[i, t, :] = char_vectors[char_seq[t]]\n",
    "            Y[i, t, :] = char_vectors[char_seq[t+1]]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 454, 76)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = get_matrices(sentences[:1])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'не мысля гордый свет забавить,\\nвниманье дружбы возлюбя,\\nхотел бы я тебе представить\\nзалог достойнее тебя,\\nдостойнее души прекрасной,\\nсвятой исполненной мечты,\\nпоэзии живой и ясной,\\nвысоких дум и простоты;\\nно так и быть — рукой пристрастной\\nприми собранье пестрых глав,\\nполусмешных, полупечальных,\\nпростонародных, идеальных,\\nнебрежный плод моих забав,\\nбессониц, легких вдохновений,\\nнезрелых и увядших лет,\\nума холодных наблюдений\\nи сердца горестных замет.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'л'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_chars[np.argmax(X[0][7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_chars[np.argmax(Y[0][7])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для экономии памяти и ускорения мы вместо единичек и нулей ставим булевы значеия TRUE и FALSE. Обратите внимание, что мы в начало каждого предложения и в его конец добавили особые символы и дополнили каждое из ни пустотами до длины максимального предложения функцией `ljust`. Наконец мы готовы к строительству нейросетки.\n",
    "\n",
    "## 2. Архитектура\n",
    "\n",
    "Построим простую модель. Добавим один уровень LSTM ячеек, результат работы которых будем пропускать через один полносвязный слой, на котором и будет происходить классификация. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation = 'tanh', \n",
    "               return_sequences = True, input_dim = num_chars))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_chars))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, None, 128)         104960    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, None, 76)          9804      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, None, 76)          0         \n",
      "=================================================================\n",
      "Total params: 114,764\n",
      "Trainable params: 114,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeDistributed() - её удалили из пакета!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура! Архитектура собралась. Прокомментируем её. \n",
    "\n",
    "* Параметр `output_dim = 128` означает, что наш слой состоит из 128 LSTM-ячеек, на этом слое в качестве функции активации используем тангенс. Можно при желании поменять на сигмоиду... \n",
    "* Параметр `input_dim = X.shape[2]` задаёт размерность входа, то есть число символов. В нашем случае это `len(chars)`.\n",
    "* Параметр `return_sequences = True` здесь самый интересный. По умолчанию LSTM-ячейка идёт по входной последовательности, в нашем случае предложению, и на выход выдаёт только самый последний рещультат. Мы бы хотели, чтобы она сохраняла всю последовательность по мере продвижения.\n",
    "\n",
    "Слой `TimeDistributed` тоже является для нас новой штукой. Его фишка в том, что веса полносвязного словя не меняются во времени. Для всех выходов из LSTM всегда используются одни и те же веса. \n",
    "\n",
    "Вся наша собранная модель нарисована на картинке ниже: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель осталось скомпилировать и начать процедуру оптимизации. Как вы помните, рекурентные нейронки страдают проблемой взрыва градиентов. Чтобы этой проблемы избежать, их купируют (обрезают). Для этого используют два параметра: \n",
    "\n",
    "* `clipnorm` будет масштабировать вектор градиента так, чтобы его норма не превысила заданного порога\n",
    "* `clipvalue` будет просто обрезать до заданного порога каждую компоненту градиента по отдельности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы почти готовы к обучению. Остались две маленькие детали. Когда мы писали функцию `get_matrices`, мы оформили её так, что размерность тензоров на выходе зависит от максимальной длины предложений на входе. Мы сделали так специально, чтобы подавать в нашу нейросетку данные батчами. Нужно обернуть функцию `get_matrices` в генератор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим тестовую выборку\n",
    "test_indices = np.random.choice(range(len(sentences)), int(len(sentences) * 0.05))\n",
    "\n",
    "sentences_train = [sentences[x] for x in set(range(len(sentences))) - set(test_indices)]\n",
    "sentences_test = [sentences[x] for x in test_indices]\n",
    "\n",
    "sentences_train = sorted(sentences_train, key = lambda x : len(x))\n",
    "X_test, y_test = get_matrices(sentences_test)\n",
    "\n",
    "batch_size = 16\n",
    "def generate_batch():\n",
    "    while True:\n",
    "        for i in range( int(len(sentences_train)/batch_size)):\n",
    "            sentences_batch = sentences_train[i*batch_size : (i+1)*batch_size]\n",
    "            yield get_matrices(sentences_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь функция `generate_batch` последовательно будет проходить наш датасет, разбивая его на мини-батчи по 16 предложений. А чтобы это имело ещё больше смысла мы предварительно отсортировали `sentences_train` по длине, так что теперь мини-батчи будут иметь последовательно увеличивающуюся ширину, предложения в них будут иметь примерно одинаковую длину и заполнять `PADDING_CHAR` придется не так много остатков. \n",
    "\n",
    "В ходе обучения модели нам часто хочется наблюдать за какими-нибудь её особенностями. В этом обычно помогают специальные функции: функции обратного вызова (callbacks). Если в этот метод передать список функций, то они будут запускаться после каждой эпохи обучения. И мы сможем отслеживать интересующую нас при обучении сетки статистику. Давайте добавим две стандартные функции обратного вызова и напишем одну свою. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу же добавляем свою. Как вы могли бы в с помнить, на самой первой паре мы говорили о Softmax. Мы говорили, что это мягкий максимум. Он при трансформации полученных для каждой категории чисел в вероятности, пытается приподнять самое большое число и приопустить маленькие, мягко выделяя максимум. \n",
    "\n",
    "Силу такого выделения можно контролировать. Для этого в формулу вшивается дополнительный параметр $T$, который называют температурой сэмплирования (см пример на странице 267 Николенко). \n",
    "\n",
    "$$ p(w) \\propto e^{-\\frac{1}{T} x_{w}} $$\n",
    "\n",
    "Если взять $T$ очень большим, то показатели экспоненты окажутся небольшими по модулю и возведения в степень будут близки. На выходе получится близкое к равномерному распределение. Сэмплирование будет довольно случайным. Взвинчивание $T$ позволяет делать сэмплирование конкретным. При $T \\to 0$ распределение будет вырожденным. \n",
    "\n",
    "Напишем колбэк, который будет подставлять в сетку разные значения температуры при генерации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class CharSampler(Callback):\n",
    "    def __init__(self, char_vectors, model):\n",
    "        self.char_vectors = char_vectors\n",
    "        self.model = model \n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch = 0\n",
    "        if os.path.isfile('output_file'):\n",
    "            os.remove('output_file')\n",
    "            \n",
    "    def sample(self, preds, temperature=1.0):\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds)/temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        return np.argmax(probas)\n",
    "    \n",
    "    def sample_one(self, T):\n",
    "        result = START_CHAR\n",
    "        while len(result) < 500:\n",
    "            Xsampled = np.zeros((1, len(result), num_chars))\n",
    "            for t,c in enumerate(list(result)):\n",
    "                Xsampled[0, t, :] = self.char_vectors[c]\n",
    "            ysampled = self.model.predict(Xsampled, batch_size=1)[0,:]\n",
    "            yv = ysampled[len(result) - 1, :]\n",
    "            selected_char = indices_to_chars[self.sample(yv, T)]\n",
    "            if selected_char == END_CHAR:\n",
    "                break\n",
    "            result = result + selected_char\n",
    "        return result\n",
    "\n",
    "    def on_epoch_end(self, batch, logs = {}):\n",
    "        self.epoch_end = self.epoch + 1\n",
    "        if self.epoch % 50 == 0:\n",
    "            print(\"\\nEpoch %d text sampling:\" % self.epoch)\n",
    "            with open('output_file', 'a') as outf:\n",
    "                outf.write('\\n======= Epoch %d =======\\n' % self.epoch)\n",
    "                for T in [0.3, 0.5, 0.7, 0.9, 1.1]:\n",
    "                    print('\\tsampling, T = %.1f...' % T)\n",
    "                    for _ in range(5):\n",
    "                        self.model.reset_states()\n",
    "                        res = self.sample_one(T)\n",
    "                        outf.write('\\nT = %.1f\\n%s\\n' % (T, res[1:]))\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в сетку ещё один колбэк для логирования результатов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "cb_logger = CSVLogger('sim/' + 'onegin' + '.log')\n",
    "cb_sampler = CharSampler(char_vectors, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец мы готовы учить. Для обучения по батчам испольщуем `fit_generate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1136/1136 [==============================] - 105s 70ms/step - loss: 3.1178 - accuracy: 0.1767 - val_loss: 0.9421 - val_accuracy: 0.7202\n",
      "\n",
      "Epoch 0 text sampling:\n",
      "\tsampling, T = 0.3...\n",
      "\tsampling, T = 0.5...\n",
      "\tsampling, T = 0.7...\n",
      "\tsampling, T = 0.9...\n",
      "\tsampling, T = 1.1...\n",
      "Epoch 2/10\n",
      "1136/1136 [==============================] - 71s 63ms/step - loss: 2.3888 - accuracy: 0.2875 - val_loss: 2.4751 - val_accuracy: 0.3018\n",
      "\n",
      "Epoch 0 text sampling:\n",
      "\tsampling, T = 0.3...\n",
      "\tsampling, T = 0.5...\n",
      "\tsampling, T = 0.7...\n",
      "\tsampling, T = 0.9...\n",
      "\tsampling, T = 1.1...\n",
      "Epoch 3/10\n",
      "1136/1136 [==============================] - 71s 62ms/step - loss: 2.2278 - accuracy: 0.3245 - val_loss: 1.4381 - val_accuracy: 0.7432\n",
      "\n",
      "Epoch 0 text sampling:\n",
      "\tsampling, T = 0.3...\n",
      "\tsampling, T = 0.5...\n",
      "\tsampling, T = 0.7...\n",
      "\tsampling, T = 0.9...\n",
      "\tsampling, T = 1.1...\n",
      "Epoch 4/10\n",
      "1136/1136 [==============================] - 73s 64ms/step - loss: 2.1198 - accuracy: 0.3501 - val_loss: 0.8833 - val_accuracy: 0.7508\n",
      "\n",
      "Epoch 0 text sampling:\n",
      "\tsampling, T = 0.3...\n",
      "\tsampling, T = 0.5...\n",
      "\tsampling, T = 0.7...\n",
      "\tsampling, T = 0.9...\n",
      "\tsampling, T = 1.1...\n",
      "Epoch 5/10\n",
      "1136/1136 [==============================] - 75s 66ms/step - loss: 2.0105 - accuracy: 0.3731 - val_loss: 0.8420 - val_accuracy: 0.7542\n",
      "\n",
      "Epoch 0 text sampling:\n",
      "\tsampling, T = 0.3...\n",
      "\tsampling, T = 0.5...\n",
      "\tsampling, T = 0.7...\n",
      "\tsampling, T = 0.9...\n",
      "\tsampling, T = 1.1...\n",
      "Epoch 6/10\n",
      "1136/1136 [==============================] - 83s 73ms/step - loss: 1.9243 - accuracy: 0.3897 - val_loss: 0.8085 - val_accuracy: 0.7557\n",
      "\n",
      "Epoch 0 text sampling:\n",
      "\tsampling, T = 0.3...\n",
      "\tsampling, T = 0.5...\n",
      "\tsampling, T = 0.7...\n",
      "\tsampling, T = 0.9...\n",
      "\tsampling, T = 1.1...\n",
      "Epoch 7/10\n",
      " 527/1136 [============>.................] - ETA: 40s - loss: 1.8298 - accuracy: 0.4114"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-7187f4edc3b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit_generator(generate_batch(),\n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1916\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1918\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generate_batch(),\n",
    "                     int(len(sentences_train) / batch_size) * batch_size,\n",
    "                     epochs=10,\n",
    "                     verbose=True, \n",
    "                     validation_data = (X_test, y_test), \n",
    "                     callbacks=[cb_logger, cb_sampler] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
